{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fb5f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXIF Capture Date (for photos) ‚Üí fallback to modified date (for videos/others).\n",
    "\n",
    "#Duplicate Detection:\n",
    "\n",
    "#First check (file size + capture date)\n",
    "\n",
    "#If same ‚Üí confirm with SHA256 hash\n",
    "\n",
    "#If hash matches ‚Üí duplicate ‚Üí delete.\n",
    "\n",
    "#If hash differs ‚Üí keep both (different content).\n",
    "\n",
    "#Organizes into folders: Year/Month structure.\n",
    "\n",
    "#Deletes originals after moving.\n",
    "\n",
    "#Optional CSV log with actions taken.\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import calendar\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "def get_media_date(file_path):\n",
    "    \"\"\"Get capture date from EXIF (for images) or fallback to modified date (for videos).\"\"\"\n",
    "    try:\n",
    "        img = Image.open(file_path)\n",
    "        exif_data = img._getexif()\n",
    "        if exif_data:\n",
    "            for tag, value in exif_data.items():\n",
    "                tag_name = TAGS.get(tag)\n",
    "                if tag_name == \"DateTimeOriginal\":\n",
    "                    dt = datetime.strptime(value, \"%Y:%m:%d %H:%M:%S\")\n",
    "                    return dt\n",
    "    except Exception:\n",
    "        pass\n",
    "    return datetime.fromtimestamp(os.path.getmtime(file_path))\n",
    "\n",
    "\n",
    "def file_hash(file_path, chunk_size=8192):\n",
    "    \"\"\"Generate SHA256 hash for a file (used to confirm duplicates).\"\"\"\n",
    "    h = hashlib.sha256()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "\n",
    "def organize_media_with_hash(source_dir, destination_dir, log_file=None):\n",
    "    extensions = (\n",
    "        '.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp',  # Images\n",
    "        '.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm', '.mt4'  # Videos + mt4\n",
    "    )\n",
    "\n",
    "    os.makedirs(destination_dir, exist_ok=True)\n",
    "    moved_count, duplicate_count = 0, 0\n",
    "    seen_files = {}  # key=(size, capture_date), value=hash\n",
    "\n",
    "    log_data = []\n",
    "\n",
    "    for root, dirs, files in os.walk(source_dir):\n",
    "        if any(x.lower() in root.lower() for x in [\n",
    "            'windows', 'program files', 'appdata', '$recycle.bin', 'system volume information'\n",
    "        ]):\n",
    "            continue\n",
    "\n",
    "        for file in files:\n",
    "            if file.lower().endswith(extensions):\n",
    "                src_path = os.path.join(root, file)\n",
    "\n",
    "                try:\n",
    "                    size = os.path.getsize(src_path)\n",
    "                    capture_date = get_media_date(src_path)\n",
    "                    sig_key = (size, capture_date.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "                    # Hash check if size + date seen before\n",
    "                    if sig_key in seen_files:\n",
    "                        filehash = file_hash(src_path)\n",
    "                        if filehash == seen_files[sig_key]:\n",
    "                            duplicate_count += 1\n",
    "                            print(f\"‚è© Duplicate removed: {src_path}\")\n",
    "                            os.remove(src_path)\n",
    "                            if log_file:\n",
    "                                log_data.append([src_path, \"DUPLICATE - Removed\", size, capture_date])\n",
    "                            continue\n",
    "                        else:\n",
    "                            # Same size+date but different content (keep it)\n",
    "                            seen_files[sig_key] = file_hash(src_path)\n",
    "\n",
    "                    else:\n",
    "                        seen_files[sig_key] = file_hash(src_path)\n",
    "\n",
    "                    # Organize into Year/Month folders\n",
    "                    year, month = capture_date.year, capture_date.month\n",
    "                    month_name = calendar.month_name[month]\n",
    "                    month_folder = f\"{month:02d}_{month_name}\"\n",
    "\n",
    "                    dest_folder = os.path.join(destination_dir, str(year), month_folder)\n",
    "                    os.makedirs(dest_folder, exist_ok=True)\n",
    "\n",
    "                    dest_path = os.path.join(dest_folder, file)\n",
    "\n",
    "                    # If name conflict, keep the latest\n",
    "                    if os.path.exists(dest_path):\n",
    "                        existing_mtime = os.path.getmtime(dest_path)\n",
    "                        if capture_date.timestamp() > existing_mtime:\n",
    "                            os.remove(dest_path)  # replace older version\n",
    "                        else:\n",
    "                            duplicate_count += 1\n",
    "                            print(f\"‚è© Skipped older conflict: {src_path}\")\n",
    "                            continue\n",
    "\n",
    "                    shutil.move(src_path, dest_path)\n",
    "                    moved_count += 1\n",
    "\n",
    "                    if log_file:\n",
    "                        log_data.append([src_path, dest_path, size, capture_date])\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Failed to process {src_path}: {e}\")\n",
    "\n",
    "    if log_file:\n",
    "        with open(log_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"Original Path\", \"New Path / Status\", \"Size (bytes)\", \"Capture Date\"])\n",
    "            writer.writerows(log_data)\n",
    "\n",
    "    print(f\"\\n‚úÖ Total media files moved: {moved_count}\")\n",
    "    print(f\"‚ö†Ô∏è  Total duplicates removed: {duplicate_count}\")\n",
    "    print(f\"üìÇ Organized media is in: {destination_dir}\")\n",
    "    if log_file:\n",
    "        print(f\"üìù Log file saved at: {log_file}\")\n",
    "\n",
    "\n",
    "# ------------------- MENU -------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üì¶ Media Organizer with Duplicate Removal (Size + Date + Hash)\\n\")\n",
    "    source = input(\"Enter the SOURCE directory to scan: \").strip('\"')\n",
    "    dest = input(\"Enter the DESTINATION directory to save organized files: \").strip('\"')\n",
    "\n",
    "    log_choice = input(\"Do you want to generate a CSV log? (y/n): \").lower()\n",
    "    log_file = None\n",
    "    if log_choice == 'y':\n",
    "        log_file = os.path.join(dest, \"media_log.csv\")\n",
    "\n",
    "    organize_media_with_hash(source, dest, log_file)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
