{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOy/olV/F9AIl2JFjS/azRO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulrainarr/mycode/blob/main/JD_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AmWIqjBuQ5D",
        "outputId": "70397e08-3169-4ef3-ec1f-fc604a1ddced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job search completed! Results saved to: job_search_results_20250806_052043.csv\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Job Search Automation Script\n",
        "Parses cover letters and searches multiple job platforms for relevant positions.\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "import csv\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Set, Optional\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from urllib.parse import urlencode, quote_plus\n",
        "import logging\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class JobListing:\n",
        "    \"\"\"Data structure for job listings\"\"\"\n",
        "    title: str\n",
        "    company: str\n",
        "    location: str\n",
        "    date_posted: str\n",
        "    description: str\n",
        "    link: str\n",
        "    platform: str\n",
        "    days_old: int = 0\n",
        "    location_score: int = 0\n",
        "\n",
        "class CoverLetterParser:\n",
        "    \"\"\"Parse cover letter to extract relevant job search parameters\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Download required NLTK data\n",
        "        try:\n",
        "            nltk.data.find('tokenizers/punkt')\n",
        "            nltk.data.find('corpora/stopwords')\n",
        "            nltk.data.find('tokenizers/punkt_tab') # Add this line to download the missing resource\n",
        "        except LookupError:\n",
        "            nltk.download('punkt')\n",
        "            nltk.download('stopwords')\n",
        "            nltk.download('punkt_tab') # Add this line to download the missing resource\n",
        "\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "        # Common job titles and skills patterns\n",
        "        self.job_title_patterns = [\n",
        "            r'software\\s+engineer', r'data\\s+scientist', r'product\\s+manager',\n",
        "            r'marketing\\s+manager', r'business\\s+analyst', r'project\\s+manager',\n",
        "            r'full\\s+stack', r'frontend', r'backend', r'devops', r'ui/ux',\n",
        "            r'sales\\s+manager', r'account\\s+manager', r'consultant'\n",
        "        ]\n",
        "\n",
        "        self.location_patterns = [\n",
        "            r'[A-Z][a-z]+,\\s*[A-Z]{2}',  # City, State\n",
        "            r'[A-Z][a-z]+\\s+[A-Z][a-z]+',  # City Name\n",
        "            r'remote', r'hybrid', r'work\\s+from\\s+home'\n",
        "        ]\n",
        "\n",
        "    def extract_keywords(self, text: str) -> Dict[str, List[str]]:\n",
        "        \"\"\"Extract job-relevant keywords from cover letter\"\"\"\n",
        "        text = text.lower()\n",
        "\n",
        "        # Extract job titles\n",
        "        job_titles = []\n",
        "        for pattern in self.job_title_patterns:\n",
        "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "            job_titles.extend(matches)\n",
        "\n",
        "        # Extract locations\n",
        "        locations = []\n",
        "        for pattern in self.location_patterns:\n",
        "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "            locations.extend(matches)\n",
        "\n",
        "        # Extract skills (common technical terms)\n",
        "        skill_keywords = [\n",
        "            'python', 'java', 'javascript', 'react', 'angular', 'node.js',\n",
        "            'sql', 'mongodb', 'aws', 'docker', 'kubernetes', 'machine learning',\n",
        "            'data analysis', 'project management', 'agile', 'scrum',\n",
        "            'marketing', 'sales', 'excel', 'powerbi', 'tableau'\n",
        "        ]\n",
        "\n",
        "        skills = [skill for skill in skill_keywords if skill in text]\n",
        "\n",
        "        # Extract general keywords (excluding stop words)\n",
        "        tokens = word_tokenize(text)\n",
        "        keywords = [word for word in tokens if word.isalpha() and\n",
        "                   len(word) > 3 and word not in self.stop_words]\n",
        "\n",
        "        return {\n",
        "            'job_titles': job_titles,\n",
        "            'locations': locations,\n",
        "            'skills': skills,\n",
        "            'keywords': keywords[:20]  # Top 20 keywords\n",
        "        }\n",
        "\n",
        "    def detect_work_preferences(self, text: str) -> Dict[str, bool]:\n",
        "        \"\"\"Detect work arrangement preferences\"\"\"\n",
        "        text = text.lower()\n",
        "        return {\n",
        "            'remote': any(term in text for term in ['remote', 'work from home', 'telecommute']),\n",
        "            'hybrid': 'hybrid' in text,\n",
        "            'onsite': any(term in text for term in ['on-site', 'office', 'in-person'])\n",
        "        }\n",
        "\n",
        "class JobSearcher:\n",
        "    \"\"\"Search job platforms for relevant positions\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
        "        })\n",
        "        self.job_listings = []\n",
        "        self.seen_jobs = set()  # To avoid duplicates\n",
        "\n",
        "    def search_linkedin_jobs(self, keywords: List[str], location: str = \"\", limit: int = 25) -> List[JobListing]:\n",
        "        \"\"\"Search LinkedIn Jobs (using their public job search)\"\"\"\n",
        "        jobs = []\n",
        "        try:\n",
        "            search_terms = ' '.join(keywords[:3])  # Use top 3 keywords\n",
        "            params = {\n",
        "                'keywords': search_terms,\n",
        "                'location': location,\n",
        "                'f_TPR': 'r604800',  # Past week\n",
        "                'sortBy': 'DD'  # Date descending\n",
        "            }\n",
        "\n",
        "            url = f\"https://www.linkedin.com/jobs/search?{urlencode(params)}\"\n",
        "\n",
        "            # Note: LinkedIn has anti-scraping measures, this is a simplified example\n",
        "            # In production, you'd use LinkedIn's API or specialized tools\n",
        "            logger.info(f\"Searching LinkedIn for: {search_terms} in {location}\")\n",
        "\n",
        "            # Simulated LinkedIn job results (replace with actual scraping/API calls)\n",
        "            for i in range(min(limit, 10)):  # Simulate finding 10 jobs\n",
        "                job = JobListing(\n",
        "                    title=f\"Software Engineer - {search_terms}\",\n",
        "                    company=f\"Tech Company {i+1}\",\n",
        "                    location=location or \"Remote\",\n",
        "                    date_posted=(datetime.now() - timedelta(days=i)).strftime(\"%Y-%m-%d\"),\n",
        "                    description=f\"Position involving {search_terms} and related technologies\",\n",
        "                    link=f\"https://linkedin.com/jobs/view/{1000000+i}\",\n",
        "                    platform=\"LinkedIn\",\n",
        "                    days_old=i\n",
        "                )\n",
        "                jobs.append(job)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error searching LinkedIn: {e}\")\n",
        "\n",
        "        return jobs\n",
        "\n",
        "    def search_indeed_jobs(self, keywords: List[str], location: str = \"\", limit: int = 25) -> List[JobListing]:\n",
        "        \"\"\"Search Indeed for jobs\"\"\"\n",
        "        jobs = []\n",
        "        try:\n",
        "            search_terms = ' '.join(keywords[:3])\n",
        "            params = {\n",
        "                'q': search_terms,\n",
        "                'l': location,\n",
        "                'fromage': '7',  # Last 7 days\n",
        "                'sort': 'date'\n",
        "            }\n",
        "\n",
        "            url = f\"https://www.indeed.com/jobs?{urlencode(params)}\"\n",
        "            logger.info(f\"Searching Indeed for: {search_terms} in {location}\")\n",
        "\n",
        "            # Simulated Indeed results\n",
        "            for i in range(min(limit, 15)):\n",
        "                job = JobListing(\n",
        "                    title=f\"{search_terms.title()} Specialist\",\n",
        "                    company=f\"Indeed Company {i+1}\",\n",
        "                    location=location or \"Various Locations\",\n",
        "                    date_posted=(datetime.now() - timedelta(days=i)).strftime(\"%Y-%m-%d\"),\n",
        "                    description=f\"Looking for experienced professional in {search_terms}\",\n",
        "                    link=f\"https://indeed.com/viewjob?jk={2000000+i}\",\n",
        "                    platform=\"Indeed\",\n",
        "                    days_old=i\n",
        "                )\n",
        "                jobs.append(job)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error searching Indeed: {e}\")\n",
        "\n",
        "        return jobs\n",
        "\n",
        "    def search_google_jobs(self, keywords: List[str], location: str = \"\", limit: int = 25) -> List[JobListing]:\n",
        "        \"\"\"Search Google Jobs\"\"\"\n",
        "        jobs = []\n",
        "        try:\n",
        "            search_terms = ' '.join(keywords[:3])\n",
        "            # Google Jobs search would require Google Custom Search API\n",
        "            logger.info(f\"Searching Google Jobs for: {search_terms} in {location}\")\n",
        "\n",
        "            # Simulated Google Jobs results\n",
        "            for i in range(min(limit, 10)):\n",
        "                job = JobListing(\n",
        "                    title=f\"Senior {search_terms.title()} Role\",\n",
        "                    company=f\"Google Partner {i+1}\",\n",
        "                    location=location or \"Multiple Locations\",\n",
        "                    date_posted=(datetime.now() - timedelta(days=i+1)).strftime(\"%Y-%m-%d\"),\n",
        "                    description=f\"Exciting opportunity in {search_terms} field\",\n",
        "                    link=f\"https://careers.google.com/jobs/results/{3000000+i}\",\n",
        "                    platform=\"Google Jobs\",\n",
        "                    days_old=i+1\n",
        "                )\n",
        "                jobs.append(job)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error searching Google Jobs: {e}\")\n",
        "\n",
        "        return jobs\n",
        "\n",
        "    def search_monster_jobs(self, keywords: List[str], location: str = \"\", limit: int = 25) -> List[JobListing]:\n",
        "        \"\"\"Search Monster.com for jobs\"\"\"\n",
        "        jobs = []\n",
        "        try:\n",
        "            search_terms = ' '.join(keywords[:3])\n",
        "            logger.info(f\"Searching Monster for: {search_terms} in {location}\")\n",
        "\n",
        "            # Simulated Monster results\n",
        "            for i in range(min(limit, 8)):\n",
        "                job = JobListing(\n",
        "                    title=f\"{search_terms.title()} Professional\",\n",
        "                    company=f\"Monster Corp {i+1}\",\n",
        "                    location=location or \"Remote/Hybrid\",\n",
        "                    date_posted=(datetime.now() - timedelta(days=i+2)).strftime(\"%Y-%m-%d\"),\n",
        "                    description=f\"Join our team working with {search_terms} technologies\",\n",
        "                    link=f\"https://monster.com/job-openings/{4000000+i}\",\n",
        "                    platform=\"Monster\",\n",
        "                    days_old=i+2\n",
        "                )\n",
        "                jobs.append(job)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error searching Monster: {e}\")\n",
        "\n",
        "        return jobs\n",
        "\n",
        "class JobFilter:\n",
        "    \"\"\"Filter and rank job listings based on criteria\"\"\"\n",
        "\n",
        "    def __init__(self, preferred_locations: List[str], work_preferences: Dict[str, bool]):\n",
        "        self.preferred_locations = [loc.lower() for loc in preferred_locations]\n",
        "        self.work_preferences = work_preferences\n",
        "\n",
        "    def calculate_location_score(self, job_location: str) -> int:\n",
        "        \"\"\"Calculate location relevance score\"\"\"\n",
        "        location_lower = job_location.lower()\n",
        "        score = 0\n",
        "\n",
        "        # Check for remote/hybrid preferences\n",
        "        if self.work_preferences.get('remote') and any(term in location_lower for term in ['remote', 'work from home']):\n",
        "            score += 10\n",
        "        if self.work_preferences.get('hybrid') and 'hybrid' in location_lower:\n",
        "            score += 8\n",
        "\n",
        "        # Check preferred locations\n",
        "        for pref_loc in self.preferred_locations:\n",
        "            if pref_loc in location_lower:\n",
        "                score += 15\n",
        "\n",
        "        return score\n",
        "\n",
        "    def filter_and_rank(self, jobs: List[JobListing]) -> List[JobListing]:\n",
        "        \"\"\"Filter duplicates and rank jobs\"\"\"\n",
        "        # Remove duplicates based on title and company\n",
        "        unique_jobs = {}\n",
        "        for job in jobs:\n",
        "            key = f\"{job.title.lower()}_{job.company.lower()}\"\n",
        "            if key not in unique_jobs:\n",
        "                unique_jobs[key] = job\n",
        "\n",
        "        filtered_jobs = list(unique_jobs.values())\n",
        "\n",
        "        # Calculate location scores\n",
        "        for job in filtered_jobs:\n",
        "            job.location_score = self.calculate_location_score(job.location)\n",
        "\n",
        "        # Sort by recency (days_old) and location score\n",
        "        ranked_jobs = sorted(filtered_jobs,\n",
        "                           key=lambda x: (-x.location_score, x.days_old))\n",
        "\n",
        "        return ranked_jobs\n",
        "\n",
        "class JobSearchAutomation:\n",
        "    \"\"\"Main automation class that coordinates the entire process\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.parser = CoverLetterParser()\n",
        "        self.searcher = JobSearcher()\n",
        "\n",
        "    def process_cover_letter(self, cover_letter_path: str) -> Dict:\n",
        "        \"\"\"Process cover letter file and extract job search parameters\"\"\"\n",
        "        try:\n",
        "            with open(cover_letter_path, 'r', encoding='utf-8') as file:\n",
        "                content = file.read()\n",
        "\n",
        "            keywords = self.parser.extract_keywords(content)\n",
        "            work_preferences = self.parser.detect_work_preferences(content)\n",
        "\n",
        "            return {\n",
        "                'keywords': keywords,\n",
        "                'work_preferences': work_preferences,\n",
        "                'raw_content': content\n",
        "            }\n",
        "        except FileNotFoundError:\n",
        "            logger.error(f\"Cover letter file not found: {cover_letter_path}\")\n",
        "            return {}\n",
        "\n",
        "    def search_all_platforms(self, search_params: Dict) -> List[JobListing]:\n",
        "        \"\"\"Search all job platforms\"\"\"\n",
        "        all_jobs = []\n",
        "        keywords = search_params['keywords']\n",
        "\n",
        "        # Use job titles and skills as search terms\n",
        "        search_terms = keywords.get('job_titles', []) + keywords.get('skills', [])\n",
        "        primary_location = keywords.get('locations', [''])[0] if keywords.get('locations') else ''\n",
        "\n",
        "        # Search each platform\n",
        "        platforms = [\n",
        "            self.searcher.search_linkedin_jobs,\n",
        "            self.searcher.search_indeed_jobs,\n",
        "            self.searcher.search_google_jobs,\n",
        "            self.searcher.search_monster_jobs\n",
        "        ]\n",
        "\n",
        "        for search_func in platforms:\n",
        "            try:\n",
        "                jobs = search_func(search_terms, primary_location, limit=15)\n",
        "                all_jobs.extend(jobs)\n",
        "                time.sleep(2)  # Rate limiting\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error in {search_func.__name__}: {e}\")\n",
        "\n",
        "        return all_jobs\n",
        "\n",
        "    def generate_report(self, jobs: List[JobListing], output_format: str = 'csv') -> str:\n",
        "        \"\"\"Generate job report in specified format\"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "        if output_format.lower() == 'csv':\n",
        "            filename = f\"job_search_results_{timestamp}.csv\"\n",
        "            with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "                fieldnames = ['Title', 'Company', 'Location', 'Date Posted',\n",
        "                             'Platform', 'Days Old', 'Location Score', 'Link', 'Description']\n",
        "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "                writer.writeheader()\n",
        "                for job in jobs:\n",
        "                    writer.writerow({\n",
        "                        'Title': job.title,\n",
        "                        'Company': job.company,\n",
        "                        'Location': job.location,\n",
        "                        'Date Posted': job.date_posted,\n",
        "                        'Platform': job.platform,\n",
        "                        'Days Old': job.days_old,\n",
        "                        'Location Score': job.location_score,\n",
        "                        'Link': job.link,\n",
        "                        'Description': job.description[:200] + '...' if len(job.description) > 200 else job.description\n",
        "                    })\n",
        "\n",
        "        elif output_format.lower() == 'excel':\n",
        "            filename = f\"job_search_results_{timestamp}.xlsx\"\n",
        "            df = pd.DataFrame([{\n",
        "                'Title': job.title,\n",
        "                'Company': job.company,\n",
        "                'Location': job.location,\n",
        "                'Date Posted': job.date_posted,\n",
        "                'Platform': job.platform,\n",
        "                'Days Old': job.days_old,\n",
        "                'Location Score': job.location_score,\n",
        "                'Link': job.link,\n",
        "                'Description': job.description[:200] + '...' if len(job.description) > 200 else job.description\n",
        "            } for job in jobs])\n",
        "            df.to_excel(filename, index=False)\n",
        "\n",
        "        return filename\n",
        "\n",
        "    def run_automation(self, cover_letter_path: str, output_format: str = 'csv', max_results: int = 20) -> str:\n",
        "        \"\"\"Run the complete job search automation\"\"\"\n",
        "        logger.info(\"Starting job search automation...\")\n",
        "\n",
        "        # Step 1: Process cover letter\n",
        "        search_params = self.process_cover_letter(cover_letter_path)\n",
        "        if not search_params:\n",
        "            return \"Error: Could not process cover letter\"\n",
        "\n",
        "        logger.info(f\"Extracted keywords: {search_params['keywords']}\")\n",
        "        logger.info(f\"Work preferences: {search_params['work_preferences']}\")\n",
        "\n",
        "        # Step 2: Search all platforms\n",
        "        logger.info(\"Searching job platforms...\")\n",
        "        all_jobs = self.search_all_platforms(search_params)\n",
        "        logger.info(f\"Found {len(all_jobs)} total job listings\")\n",
        "\n",
        "        # Step 3: Filter and rank jobs\n",
        "        job_filter = JobFilter(\n",
        "            preferred_locations=search_params['keywords'].get('locations', []),\n",
        "            work_preferences=search_params['work_preferences']\n",
        "        )\n",
        "\n",
        "        ranked_jobs = job_filter.filter_and_rank(all_jobs)\n",
        "        top_jobs = ranked_jobs[:max_results]\n",
        "\n",
        "        logger.info(f\"Filtered to top {len(top_jobs)} relevant positions\")\n",
        "\n",
        "        # Step 4: Generate report\n",
        "        report_file = self.generate_report(top_jobs, output_format)\n",
        "        logger.info(f\"Report generated: {report_file}\")\n",
        "\n",
        "        return report_file\n",
        "\n",
        "# Example usage\n",
        "def main():\n",
        "    \"\"\"Example usage of the job search automation\"\"\"\n",
        "    automation = JobSearchAutomation()\n",
        "\n",
        "    # For demonstration, create a sample cover letter\n",
        "    sample_cover_letter = \"\"\"\n",
        "    Dear Hiring Manager,\n",
        "\n",
        "    I am writing to express my interest in software engineering positions, particularly\n",
        "    in Python development and machine learning roles. With 5 years of experience in\n",
        "    full-stack development using Python, JavaScript, React, and SQL, I am seeking\n",
        "    opportunities in San Francisco, CA or remote positions.\n",
        "\n",
        "    My background includes working with AWS, Docker, and agile methodologies. I am\n",
        "    particularly interested in data science roles and would prefer hybrid or remote\n",
        "    work arrangements.\n",
        "\n",
        "    Best regards,\n",
        "    [Your Name]\n",
        "    \"\"\"\n",
        "\n",
        "    # Save sample cover letter\n",
        "    with open('Cover_letter.txt', 'w') as f:\n",
        "        f.write(sample_cover_letter)\n",
        "\n",
        "    # Run automation\n",
        "    try:\n",
        "        result_file = automation.run_automation('Cover_letter.txt', 'csv', 20)\n",
        "        print(f\"Job search completed! Results saved to: {result_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error running automation: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}